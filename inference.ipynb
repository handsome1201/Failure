{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/handsome1201/Failure/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1m6kDCbwLLS"
      },
      "source": [
        "# Bar graph & Circle graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2RaqP5rnwZXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251c10d9-6346-4611-cba0-e9f9ca795b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FieDlZJOvZ1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99e06d17-3291-4dcc-cd34-3d786cecdc99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/175.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=45d5aeb5aba09cbb22b595b3124167fc9a627b84a66c0073aff35595c3d2a4c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 5.1\n",
            "    Uninstalling PyYAML-5.1:\n",
            "      Successfully uninstalled PyYAML-5.1\n",
            "Successfully installed pyyaml-5.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: extcolors in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from extcolors) (8.4.0)\n",
            "Requirement already satisfied: convcolors>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from extcolors) (2.2.0)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.15.2+cu118)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.8.0.74)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (8.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (5.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.1)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post4)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->easyocr) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easyocr) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->easyocr) (16.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2023.7.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (23.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->easyocr) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml==5.4.1\n",
        "!pip install extcolors\n",
        "!pip install easyocr\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import easyocr\n",
        "import xml.etree.ElementTree as ET\n",
        "import extcolors\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 그래프 종류 판별"
      ],
      "metadata": {
        "id": "MkxzFjH-RegQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wrong_detect_delete(data):\n",
        "  count=0\n",
        "  number=re.compile('[\\d]')\n",
        "  out_str=''\n",
        "  for j in data :\n",
        "      j = list(j)\n",
        "      for alphabet in j:\n",
        "          if number.match(alphabet)!=None:\n",
        "              out_str+=alphabet\n",
        "          elif alphabet==',' or alphabet=='.':\n",
        "              out_str+=alphabet\n",
        "\n",
        "  if data[-1]!=\"%\" and len(out_str)>5 and (out_str[len(out_str)-2:len(out_str)] =='96') | (out_str[len(out_str)-2:len(out_str)] =='95') | (out_str[len(out_str)-2:len(out_str)] =='36'):\n",
        "\n",
        "      out_str = list(out_str)\n",
        "\n",
        "      out_str[len(out_str)-2:len(out_str)] = ''\n",
        "      out_str=''.join(out_str)\n",
        "  return out_str"
      ],
      "metadata": {
        "id": "e_Ft8aBUwJly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Vertical(image_path):\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      reader = easyocr.Reader(['en', 'ko'], gpu=True)\n",
        "  else:\n",
        "      reader = easyocr.Reader(['en', 'ko'], gpu=False)\n",
        "\n",
        "  result = reader.readtext(image_path)\n",
        "\n",
        "  img = Image.open(image_path)\n",
        "  img_array = np.array(img)\n",
        "  gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "  result = reader.readtext(gray)\n",
        "\n",
        "  grouped_values = {}\n",
        "\n",
        "  for i in range(len(result)):\n",
        "      text = wrong_detect_delete(result[i][1])\n",
        "\n",
        "      # 그림 단어가 포함되어 있는 경우\n",
        "      if '그림' in text:\n",
        "          grouped_values['제목'] = text\n",
        "      else:\n",
        "          x, y = min(list(_[0] for _ in result[i][0])), min(list(_[1] for _ in result[i][0]))\n",
        "\n",
        "          # 값의 차이가 25 이하인 값을 찾아서 묶어줍니다\n",
        "          for j in range(i - 1, -1, -1):\n",
        "              if abs(min(list(_[0] for _ in result[j][0])) - x) <= 25:\n",
        "                  if y < min(list(_[1] for _ in result[j][0])):\n",
        "                      grouped_values[text] = result[j][1]\n",
        "                  else:\n",
        "                      grouped_values[result[j][1]] = text\n",
        "                  break\n",
        "\n",
        "  # Vertical 함수 호출 및 결과 출력\n",
        "  grouped_values = Vertical(image_path)\n",
        "  for key, value in grouped_values.items():\n",
        "      grouped_values[key] = wrong_detect_delete(value)\n",
        "\n",
        "  return grouped_values"
      ],
      "metadata": {
        "id": "9T6KqNIjPGP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Horizontal(image_path):\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "      reader = easyocr.Reader(['en', 'ko'], gpu=True)\n",
        "  else:\n",
        "      reader = easyocr.Reader(['en', 'ko'], gpu=False)\n",
        "\n",
        "  result = reader.readtext(image_path)\n",
        "\n",
        "  img = Image.open(image_path)\n",
        "  img_array = np.array(img)\n",
        "  gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "  result = reader.readtext(gray)\n",
        "\n",
        "  grouped_values = {}\n",
        "\n",
        "  # 그림으로 시작하는 단어가 있을 경우 '제목'으로 key값 설정\n",
        "  for i in range(len(result)):\n",
        "      if result[i][1].startswith('그림'):\n",
        "          grouped_values['제목'] = result[i][1]\n",
        "          break\n",
        "\n",
        "  for i in range(len(result)):\n",
        "      text = result[i][1]\n",
        "      x, y = min(list(_[0] for _ in result[i][0])), min(list(_[1] for _ in result[i][0]))\n",
        "\n",
        "      # 값의 차이가 25 이하인 값을 찾아서 묶어줍니다\n",
        "      for j in range(i - 1, -1, -1):\n",
        "          if abs(min(list(_[1] for _ in result[j][0])) - y) <= 25:\n",
        "              if x < min(list(_[0] for _ in result[j][0])):\n",
        "                  grouped_values[text] = result[j][1]\n",
        "              else:\n",
        "                  grouped_values[result[j][1]] = text\n",
        "              break\n",
        "\n",
        "  # Vertical 함수 호출 및 결과 출력\n",
        "  grouped_values = Vertical(image_path)\n",
        "  for key, value in grouped_values.items():\n",
        "      grouped_values[key] = wrong_detect_delete(value)\n",
        "\n",
        "\n",
        "  return grouped_values"
      ],
      "metadata": {
        "id": "wCHDznq9tqfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def circle(image_path):\n",
        "\n",
        "  def compare_rgb_tuple(rgb1, rgb2):  # 두 rgb 값들이 유사한지를 판단해 boolean으로 반환하는 함수\n",
        "      root = ET.Element(\"root\")\n",
        "      r_diff_abs = abs(rgb1[0] - rgb2[0])\n",
        "      g_diff_abs = abs(rgb1[1] - rgb2[1])\n",
        "      b_diff_abs = abs(rgb1[2] - rgb2[2])\n",
        "      tot_abs = r_diff_abs + g_diff_abs + b_diff_abs\n",
        "      if r_diff_abs<30 and g_diff_abs<30 and b_diff_abs<30 and tot_abs<70 :\n",
        "          return True\n",
        "      return False\n",
        "\n",
        "  img = Image.open(image_path)  # 이미지 열기\n",
        "  rgb_img = img.convert(\"RGB\")\n",
        "\n",
        "  reader = easyocr.Reader(['ko','en'], gpu=True)    # ocr로 이미지 읽기\n",
        "  result1 = reader.readtext(image_path)\n",
        "\n",
        "  num = len(result1)\n",
        "  text_list=[]  # ocr로 읽은 text list\n",
        "  color_list=[] # text가 위치한 곳의 color list\n",
        "  grouped_values = {}\n",
        "  title_loc=0\n",
        "  istitle=0\n",
        "\n",
        "  for i in range(num):          #제목이 있는 경우 제목을 분리\n",
        "    if len(result1[i][1])>2:\n",
        "        if '그림' in result1[i][1]:\n",
        "            grouped_values['제목']=result1[i][1]\n",
        "            title_loc=i\n",
        "            istitle=1\n",
        "\n",
        "  if istitle==1:\n",
        "    result1.remove(result1[title_loc])\n",
        "  num = len(result1)\n",
        "\n",
        "  for i in range(num):  # text가 위치한 곳의 rgb 값을 읽어옴.\n",
        "      min_x=result1[i][0][0][0]\n",
        "      min_y=result1[i][0][0][1]\n",
        "      width=0\n",
        "      height=0\n",
        "      text_list.append(result1[i][1])\n",
        "\n",
        "      for j in range(3):\n",
        "          j=j+1\n",
        "          if min_x>=result1[i][0][j][0]:\n",
        "              min_x=result1[i][0][j][0]\n",
        "          else :\n",
        "              width = result1[i][0][j][0]-min_x\n",
        "          if min_y>=result1[i][0][j][1]:\n",
        "              min_y=result1[i][0][j][1]\n",
        "          else :\n",
        "              height = result1[i][0][j][1]-min_y\n",
        "      crop_img = rgb_img.crop((min_x, min_y, min_x+width, min_y+height))\n",
        "      crop_img.save('tb_img_ext'+str(i)+'.png', 'png')\n",
        "      saved_croped_img = Image.open('tb_img_ext'+str(i)+'.png')\n",
        "      colors, _ = extcolors.extract_from_image(saved_croped_img, limit=1)\n",
        "      for c in colors:\n",
        "          color_list.append(c[0])\n",
        "      os.remove('tb_img_ext'+str(i)+'.png')\n",
        "\n",
        "  rgb_group=[]\n",
        "  group=[]\n",
        "  arr_count=0\n",
        "  filled_group=0\n",
        "\n",
        "  for rgb_val in color_list:    # text의 rgb 값이 겹치는 것끼리 group화\n",
        "      if len(rgb_group)==0 :\n",
        "          rgb_group.append(rgb_val)\n",
        "          group.append([])\n",
        "          group[filled_group].append(text_list[arr_count])\n",
        "          filled_group+=1\n",
        "\n",
        "      else :\n",
        "          is_old=0\n",
        "          group_count=0\n",
        "          for selected_rgb in rgb_group:\n",
        "              if compare_rgb_tuple(selected_rgb, rgb_val):\n",
        "                  group[group_count].append(text_list[arr_count])\n",
        "                  is_old=1\n",
        "                  break\n",
        "\n",
        "              group_count+=1\n",
        "          if is_old==0:\n",
        "              rgb_group.append(rgb_val)\n",
        "              group.append([])\n",
        "              group[filled_group].append(text_list[arr_count])\n",
        "              filled_group+=1\n",
        "      arr_count+=1\n",
        "  merged_group=[]\n",
        "  count=0\n",
        "\n",
        "  for i in group :      # group화된 text들을 배경색을 기준으로 나누어 저장\n",
        "      out_str=''\n",
        "      merged_group.append([[],[]])\n",
        "\n",
        "      for j in i:\n",
        "          if (j[len(j)-2:len(j)] =='96') | (j[len(j)-2:len(j)] =='95') | (j[len(j)-2:len(j)] =='36'):\n",
        "              j = list(j)\n",
        "              j[len(j)-2:len(j)] = ''\n",
        "              ''.join(j)\n",
        "              out_percent=''\n",
        "              for k in j:\n",
        "                  out_percent+=str(k)\n",
        "              merged_group[count][1].append(out_percent)\n",
        "              check=1\n",
        "          else :\n",
        "              out_str+=j\n",
        "\n",
        "      merged_group[count][0].append(out_str)\n",
        "      count+=1\n",
        "\n",
        "  number=re.compile('[\\d]')\n",
        "\n",
        "  for i in merged_group:            # group 내의 항목과 항목값을 분류\n",
        "      out_str1=''\n",
        "      out_num1=''\n",
        "      out_str2=''\n",
        "      out_num2=''\n",
        "\n",
        "      for j in i[0]:\n",
        "          j=list(j)\n",
        "          for alphabet in j:\n",
        "            if number.match(alphabet)!=None:\n",
        "                out_num1+=alphabet\n",
        "            elif alphabet==',' or alphabet=='.' or alphabet=='%':\n",
        "                out_num1+=alphabet\n",
        "            else:\n",
        "                out_str1+=alphabet\n",
        "\n",
        "      for j in i[1]:\n",
        "          j=list(j)\n",
        "          for alphabet in j:\n",
        "            if number.match(alphabet)!=None:\n",
        "                out_num2+=alphabet\n",
        "            elif alphabet==',' or alphabet=='.'or alphabet=='%':\n",
        "                out_num2+=alphabet\n",
        "            else:\n",
        "                out_str2+=alphabet\n",
        "\n",
        "      if out_num1!='' and out_str1!='':\n",
        "\n",
        "          if out_num2!='' and out_str2!='':\n",
        "            grouped_values[out_str1]=out_num1\n",
        "            grouped_values[out_str2]=out_num2\n",
        "\n",
        "          elif out_num2=='' and out_str2!='':\n",
        "            grouped_values[out_str1+out_str2]=out_num1\n",
        "          else:\n",
        "            grouped_values[out_str1]=out_num1\n",
        "\n",
        "      elif out_num2!='' and out_str2!='':\n",
        "          if out_num1!='' and out_str1!='':\n",
        "            grouped_values[out_str1]=out_num1\n",
        "            grouped_values[out_str2]=out_num2\n",
        "\n",
        "          elif out_num1=='' and out_str1!='':\n",
        "            grouped_values[out_str1+out_str2]=out_num2\n",
        "\n",
        "          else:\n",
        "            grouped_values[out_str2]=out_num2\n",
        "\n",
        "      elif out_str1!='' and out_num2!='':\n",
        "          grouped_values[out_str1]=out_num2\n",
        "      elif out_str2!='' and out_num1!='':\n",
        "          grouped_values[out_str2]=out_num1\n",
        "\n",
        "  return grouped_values"
      ],
      "metadata": {
        "id": "a5CIA80jt2ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_graph_orientation(image_path):\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self, num_classes):\n",
        "            super(Net, self).__init__()\n",
        "            self.conv = nn.Sequential(\n",
        "                nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2),\n",
        "                nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2)\n",
        "            )\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(32 * 56 * 56, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(128, num_classes)\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.conv(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "            return x\n",
        "\n",
        "    # 새로운 파일에서 사용할 모델 정의 및 초기화\n",
        "    num_classes = 2  # 이전에 학습한 모델의 클래스 개수에 맞게 설정\n",
        "    model = Net(num_classes)\n",
        "    state_dict = torch.load(\"/content/drive/MyDrive/자료/model.pth\", map_location=torch.device('cpu'))\n",
        "    model_dict = model.state_dict()\n",
        "    pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict, strict=False)\n",
        "    class_names = [\"horizontal\", \"vertical\"]\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # 이미지 크기 조정\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    outputs = model(image)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    predicted_class = class_names[predicted.item()]\n",
        "\n",
        "    if predicted_class == 'horizontal':\n",
        "        return 2\n",
        "    elif predicted_class == 'vertical':\n",
        "        return 1\n"
      ],
      "metadata": {
        "id": "qvxYkY6o_YFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_circle_orientation(image_path):\n",
        "\n",
        "    src = cv2.imread(image_path)\n",
        "    dst = src.copy()\n",
        "    gray1 = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray1, (0, 0), 1)\n",
        "    height, width = gray.shape\n",
        "    gray_len = min(height, width)\n",
        "\n",
        "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT_ALT, 1, 50, param1=300, param2=0.8, minRadius=int(gray_len / 6),\n",
        "                               maxRadius=int(gray_len / 2))\n",
        "    if circles is not None:\n",
        "        return 3"
      ],
      "metadata": {
        "id": "YcOMOwyczwxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuM26kv1yavi"
      },
      "source": [
        "### input image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/MyDrive/자료/train/vertical/수직 제목.png'\n",
        "\n",
        "if detect_circle_orientation(image_path) == 3:\n",
        "  circle(image_path)\n",
        "elif detect_graph_orientation(image_path) == 1:\n",
        "  Vertical(image_path)\n",
        "else:\n",
        "  Horizontal(image_path)"
      ],
      "metadata": {
        "id": "65x-oqxerlhm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "7fe23d83-b775-4061-ba07-03e7b2408055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5d6802660905>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mdetect_graph_orientation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mVertical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mHorizontal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-51cadc995747>\u001b[0m in \u001b[0;36mVertical\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0measyocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ko'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mreadtext\u001b[0;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         horizontal_list, free_list = self.detect(img, \n\u001b[0m\u001b[1;32m    453\u001b[0m                                                  \u001b[0mmin_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                                                  \u001b[0mlow_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cv_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         text_box_list = self.get_textbox(self.detector, \n\u001b[0m\u001b[1;32m    322\u001b[0m                                     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                                     \u001b[0mcanvas_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanvas_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mget_textbox\u001b[0;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mestimate_num_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal_num_chars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     bboxes_list, polys_list = test_net(canvas_size, mag_ratio, detector,\n\u001b[0m\u001b[1;32m     96\u001b[0m                                        \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                        \u001b[0mlink_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/detection.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[1;32m     40\u001b[0m          for n_img in img_resized_list]\n\u001b[1;32m     41\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.75 GiB total capacity; 13.65 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    reader = easyocr.Reader(['en', 'ko'], gpu=True)\n",
        "else:\n",
        "    reader = easyocr.Reader(['en', 'ko'], gpu=False)\n",
        "\n",
        "result = reader.readtext(image_path)\n",
        "\n",
        "img = Image.open(image_path)\n",
        "img_array = np.array(img)\n",
        "gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "result = reader.readtext(gray)\n",
        "\n",
        "grouped_values = {}\n",
        "\n",
        "for i in range(len(result)):\n",
        "    text = wrong_detect_delete(result[i][1])\n",
        "\n",
        "    # 그림 단어가 포함되어 있는 경우\n",
        "    if '그림' in text:\n",
        "        grouped_values['제목'] = text\n",
        "    else:\n",
        "        x, y = min(list(_[0] for _ in result[i][0])), min(list(_[1] for _ in result[i][0]))\n",
        "\n",
        "        # 값의 차이가 25 이하인 값을 찾아서 묶어줍니다\n",
        "        for j in range(i - 1, -1, -1):\n",
        "            if abs(min(list(_[0] for _ in result[j][0])) - x) <= 25:\n",
        "                if y < min(list(_[1] for _ in result[j][0])):\n",
        "                    grouped_values[text] = result[j][1]\n",
        "                else:\n",
        "                    grouped_values[result[j][1]] = text\n",
        "                break\n",
        "\n",
        "# Vertical 함수 호출 및 결과 출력\n",
        "grouped_values = Vertical(image_path)\n",
        "for key, value in grouped_values.items():\n",
        "    grouped_values[key] = wrong_detect_delete(value)\n"
      ],
      "metadata": {
        "id": "kgd5gvpn5DSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_values"
      ],
      "metadata": {
        "id": "JJO_ae839JqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uW8aV0_u_UDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}